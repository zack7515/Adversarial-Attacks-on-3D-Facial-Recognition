{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRGCv2\n",
    "num_class = 557  # depth: 557\n",
    "model_path = 'E:\\\\LED3D\\\\newData_training\\\\Resnet101\\\\bestModel.pth'  # Resnet101_focal\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Resnet101_focal\n",
    "model = models.resnet101().to(device)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_class).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "import csv\n",
    "\n",
    "image_id = []\n",
    "image_label = []\n",
    "label_map = \"E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\label_map.csv\"\n",
    "\n",
    "# 開啟 CSV 檔案 讀取label\n",
    "with open(label_map, newline='',encoding=\"utf-8-sig\") as csvfile:\n",
    "    \n",
    "    rows = csv.reader(csvfile)  \n",
    "    for row in rows:\n",
    "        image_id.append(row[0])\n",
    "        image_label.append(row[1])\n",
    "    \n",
    "class IMAGE_Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.transform = transform\n",
    "        self.num_classes = 0\n",
    "        \n",
    "        for i, _dir in enumerate(self.root_dir.glob('*')):\n",
    "            tmp_str = str(os.path.dirname(_dir))+\"\\\\\"   #windows用的是\"\\\",linux用的是\"/\"這一點要特別清楚，還有就是在寫路徑時用\"\\\\\"才表示一個\"\\\"。\n",
    "            tmp_str = str(_dir).replace(tmp_str, \"\") \n",
    "            for file in _dir.glob('*'):\n",
    "                self.x.append(file)\n",
    "                self.y.append(int(image_id.index(tmp_str)))  # 檔名代表label - > 對應的index label\n",
    "            self.num_classes += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.x[index]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.y[index], str(self.x[index])  # img, label, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整個資料集測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# eval\n",
    "# 改成所需的class\n",
    "num_class = 557  # depth: 557\n",
    "model_path = 'E:\\\\LED3D\\\\newData_training\\\\Resnet101\\\\bestModel.pth'  # Resnet101_focal\n",
    "batch_size = 64\n",
    "\n",
    "# Resnet101_focal\n",
    "model = models.resnet101().to(device)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_class).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "model.eval()\n",
    "      \n",
    "mean=[0.5, 0.5, 0.5]\n",
    "std=[0.5, 0.5, 0.5]\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "depth_path = ['F:\\\\PointCloud_Attack\\\\adv_data\\\\depth_adv_mean=0_std=5']\n",
    "normal_path = ['F:\\\\PointCloud_Attack\\\\adv_data\\\\normal_adv_mean=0_std=5']\n",
    "# attack = ['fgsm', 'bim', 'pgd']\n",
    "\n",
    "for idx in depth_path:\n",
    "    Depth_dir = os.path.join(idx)\n",
    "    Depth_ds = IMAGE_Dataset(Depth_dir,trans)\n",
    "    \n",
    "    Depth_dataloaders = DataLoader(\n",
    "        Depth_ds, \n",
    "        batch_size= batch_size, \n",
    "        pin_memory=False,  \n",
    "        shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    ssim_score = 0\n",
    "    wrong = []\n",
    "\n",
    "    for images, labels, paths in tqdm(Depth_dataloaders):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        total += int(images.shape[0])\n",
    "        correct += (preds == labels).sum()\n",
    "        \n",
    "        for t in range(int(images.shape[0])):\n",
    "            label = os.path.basename(paths[t]).split('d')[0]\n",
    "            name = os.path.basename(paths[t]).split('_depth')[0]\n",
    "            img_path = os.path.join('E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Depth', label, name)\n",
    "            image1 = io.imread(paths[t], as_gray=True)  # [256,256,3]\n",
    "            image2 = io.imread(img_path + '_nu.png', as_gray=True)  # [256,256,3]\n",
    "            ssim_score += ssim(image1, image2, multichannel=False)\n",
    "        \n",
    "    print('This is Depth image ' + ' attack test:')\n",
    "    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))\n",
    "    print('number of correct: ', float(correct))\n",
    "    print('ssim_value = {}%'.format(round((ssim_score*100/total), 5)))\n",
    "    print('total: ', int(total))\n",
    "\n",
    "        \n",
    "torch.cuda.empty_cache()\n",
    "print('-------------------------------------')\n",
    "\n",
    "for idx in normal_path: \n",
    "    Normal_dir = os.path.join(idx)\n",
    "    Normal_ds = IMAGE_Dataset(Normal_dir,trans)\n",
    "\n",
    "    Normal_dataloaders = DataLoader(\n",
    "        Normal_ds, \n",
    "        batch_size= batch_size, \n",
    "        pin_memory=False,  \n",
    "        shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    ssim_score = 0\n",
    "    wrong = []\n",
    "\n",
    "    for images, labels, paths in tqdm(Normal_dataloaders):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        total += int(images.shape[0])\n",
    "        correct += (preds == labels).sum()\n",
    "        \n",
    "        \n",
    "        for t in range(int(images.shape[0])):\n",
    "            label = os.path.basename(paths[t]).split('d')[0]\n",
    "            name = os.path.basename(paths[t]).split('_normal')[0]\n",
    "            img_path = os.path.join('E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Normal', label, name)\n",
    "            image1 = io.imread(paths[t], as_gray=False)  # [256,256,3]\n",
    "            image2 = io.imread(img_path + '_nu.png', as_gray=False)  # [256,256,3]\n",
    "            ssim_score += ssim(image1, image2, multichannel=True)\n",
    "            \n",
    "            # 記錄錯誤 csv\n",
    "            # if preds[t] != labels[t]:\n",
    "            #     wrong.append([paths[t], preds[t], labels[t]])\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    print('This is Normal image ' +  ' attack test:')    \n",
    "    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))\n",
    "    print('number of correct: ', float(correct))\n",
    "    print('ssim_value = {}%'.format(round((ssim_score*100/total), 5)))\n",
    "    print('total: ', int(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "單樣本測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# 定義圖像預處理步驟\n",
    "mean=[0.5, 0.5, 0.5]\n",
    "std=[0.5, 0.5, 0.5]\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# 讀取圖像\n",
    "img_path=['04213d241_depth.png', '04213d241_normal.png', \n",
    "          '04213d241_heatmap_gausian_z_0-5_depth.png', '04213d241_heatmap_gausian_z_0-5_normal.png']\n",
    "for path in img_path:\n",
    "    input_image = Image.open(path).convert('RGB')\n",
    "\n",
    "    # 預處理圖像\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    input_batch = input_batch.to(device)\n",
    "\n",
    "    # 模型推斷\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    # 獲取分類結果\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    print('File Name: ', path)\n",
    "    print(f\"Predicted class: {predicted.item()}\")\n",
    "    print('image_id:', image_id[predicted.item()])\n",
    "    print('\\n')\n",
    "    \n",
    "image0 = io.imread(img_path[0], as_gray=True)  # [256,256,1]\n",
    "image2 = io.imread(img_path[2], as_gray=True)  # [256,256,1]\n",
    "ssim_score1 = ssim(image0, image2, multichannel=False)\n",
    "\n",
    "image1 = io.imread(img_path[1], as_gray=False)  # [256,256,3]\n",
    "image3 = io.imread(img_path[3], as_gray=False)  # [256,256,3]\n",
    "ssim_score2 = ssim(image1, image3, multichannel=True)\n",
    "print('depth image ssim:', ssim_score1)\n",
    "print('normal image ssim:', ssim_score2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
