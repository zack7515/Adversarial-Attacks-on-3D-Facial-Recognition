{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Heat map -> CAM\n",
    "\n",
    "https://github.com/jacobgil/pytorch-grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from cam import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRGCv2\n",
    "num_class = 557  # depth: 557\n",
    "model_path = 'E:\\\\LED3D\\\\newData_training\\\\Resnet101\\\\bestModel.pth'  # Resnet101_focal\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Resnet101_focal\n",
    "model = models.resnet101().to(device)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_class).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heatmap - GradCAM define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model define\n",
    "target_layers = [model.layer4[-1]]\n",
    "# target_layers = [model.layer2[-1]]\n",
    "# target_layers = [model.layer3[-1]]\n",
    "# cam = GradCAM(model=model, target_layers=target_layers, use_cuda=device)\n",
    "cam = EigenGradCAM(model=model, target_layers=target_layers, use_cuda=device)\n",
    "targets = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "import csv\n",
    "\n",
    "image_id = []\n",
    "image_label = []\n",
    "label_map = \"E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\label_map.csv\"\n",
    "\n",
    "# 開啟 CSV 檔案 讀取label\n",
    "with open(label_map, newline='',encoding=\"utf-8-sig\") as csvfile:\n",
    "    \n",
    "    rows = csv.reader(csvfile)  \n",
    "    for row in rows:\n",
    "        image_id.append(row[0])\n",
    "        image_label.append(row[1])\n",
    "    \n",
    "class IMAGE_Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.transform = transform\n",
    "        self.num_classes = 0\n",
    "        #print(self.root_dir.name)\n",
    "        \n",
    "        for i, _dir in enumerate(self.root_dir.glob('*')):\n",
    "            tmp_str = str(os.path.dirname(_dir))+\"\\\\\"\n",
    "            tmp_str = str(_dir).replace(tmp_str, \"\") \n",
    "            for file in _dir.glob('*'):\n",
    "                self.x.append(file)\n",
    "                self.y.append(int(image_id.index(tmp_str)))  # 檔名代表label - > 對應的index label\n",
    "            self.num_classes += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.x[index]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.y[index], str(self.x[index])  # img, label, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnNormalize(tensor, mean, std):\n",
    "    unnormalized_tensor = torch.clone(tensor).detach()\n",
    "    with torch.no_grad():\n",
    "        for t in unnormalized_tensor:\n",
    "            for c, m, s in zip(t, mean, std):\n",
    "                c.mul_(s).add_(m)\n",
    "    return unnormalized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "針對heatmap區域做梯度計算\n",
    "找出紋理較粗糙區域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cal(mask_array, photo, threshold=10):  # mask_array = at_map\n",
    "    mask_array = (mask_array > 127)\n",
    "    \n",
    "    # 找出mask區域\n",
    "    non_zero_indices = np.nonzero(mask_array)  # 找到非零值的索引\n",
    "    min_row, min_col = np.min(non_zero_indices[0]), np.min(non_zero_indices[1])  # 找到最小行和列\n",
    "    max_row, max_col = np.max(non_zero_indices[0]), np.max(non_zero_indices[1])  # 找到最大行和列\n",
    "\n",
    "    # 建立全黑圖\n",
    "    blank_image = Image.new('L', photo.size, 0)\n",
    "    photo_array = np.array(photo)\n",
    "\n",
    "    # mask 對應原圖的區域\n",
    "    cropped_photo = photo_array[min_row:max_row+1, min_col:max_col+1]\n",
    "\n",
    "    # Sobel 算子計算圖片的梯度\n",
    "    sobel_x = cv2.Sobel(cropped_photo, cv2.CV_64F, 1, 0, ksize=3)  # 水平方向的梯度\n",
    "    sobel_y = cv2.Sobel(cropped_photo, cv2.CV_64F, 0, 1, ksize=3)  # 垂直方向的梯度\n",
    "\n",
    "    # 計算梯度大小\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "    # 根據閾值將梯度幅度影像進行二值化\n",
    "    binary_gradient = np.where(gradient_magnitude > threshold, 255, 0)\n",
    "    \n",
    "    # 把運算好結果貼回全黑區域\n",
    "    cropped_binary_gradient_image = Image.fromarray(binary_gradient.astype(np.uint8))\n",
    "    blank_image.paste(cropped_binary_gradient_image, (min_col, min_row))\n",
    "    \n",
    "    # 保存結果影像\n",
    "    # blank_image.save('grad_mask.png')\n",
    "    \n",
    "    return blank_image  # grad_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成對抗樣本 (Depth and Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgsm import *\n",
    "from bim import *\n",
    "from pgd import *\n",
    "\n",
    "mean=[0.5, 0.5, 0.5]\n",
    "std=[0.5, 0.5, 0.5]\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# 0908newData\n",
    "Depth_dir = 'E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Depth'\n",
    "Normal_dir = 'E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Normal'\n",
    "\n",
    "Depth_ds = IMAGE_Dataset(Depth_dir,trans)\n",
    "Normal_ds = IMAGE_Dataset(Normal_dir,trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各個make layer 的 heatmap (測試使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "cam1 = EigenGradCAM(model=model, target_layers=[model.layer1[-1]], use_cuda=device)\n",
    "cam2 = EigenGradCAM(model=model, target_layers=[model.layer2[-1]], use_cuda=device)\n",
    "cam3 = EigenGradCAM(model=model, target_layers=[model.layer3[-1]], use_cuda=device)\n",
    "targets = None\n",
    "\n",
    "dataloaders = DataLoader(\n",
    "    Normal_ds, \n",
    "    batch_size= batch_size, \n",
    "    pin_memory=False,  \n",
    "    shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "start = time.time()\n",
    "# ssim_value=0\n",
    "\n",
    "mask_path1 = 'F:\\\\pytorch-grad-cam-master\\\\normal_model\\\\adv_mask_normal50\\\\mask_layer1'\n",
    "os.makedirs(mask_path1, exist_ok=True)\n",
    "mask_path2 = 'F:\\\\pytorch-grad-cam-master\\\\normal_model\\\\adv_mask_normal50\\\\mask_layer2'\n",
    "os.makedirs(mask_path2, exist_ok=True)\n",
    "mask_path3 = 'F:\\\\pytorch-grad-cam-master\\\\normal_model\\\\adv_mask_normal50\\\\mask_layer3'\n",
    "os.makedirs(mask_path3, exist_ok=True)\n",
    "\n",
    "\n",
    "for images, labels, paths in tqdm(dataloaders):\n",
    "    # at_map = None\n",
    "    grayscale_cam = cam1(input_tensor=images, targets=targets)\n",
    "    attention = grayscale_cam * 255\n",
    "    at_map = torch.from_numpy(attention)  # [batch, width, height]\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        # save images\n",
    "        label = os.path.basename(paths[i]).split('d')[0]\n",
    "        name = os.path.basename(paths[i])\n",
    "        os.makedirs(os.path.join(mask_path1, str(label)), exist_ok=True)\n",
    "        img = transforms.ToPILImage()(at_map[i] / 255).convert('L')\n",
    "        img.save(os.path.join(mask_path1, str(label), name), \"PNG\")\n",
    "        \n",
    "    grayscale_cam = cam2(input_tensor=images, targets=targets)\n",
    "    attention = grayscale_cam * 255\n",
    "    at_map = torch.from_numpy(attention)  # [batch, width, height]\n",
    "    # print('image shape:', images.shape)\n",
    "    # print('at_map shape:', at_map.shape)\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        # save images\n",
    "        label = os.path.basename(paths[i]).split('d')[0]\n",
    "        name = os.path.basename(paths[i])\n",
    "        os.makedirs(os.path.join(mask_path2, str(label)), exist_ok=True)\n",
    "        img = transforms.ToPILImage()(at_map[i] / 255).convert('L')\n",
    "        img.save(os.path.join(mask_path2, str(label), name), \"PNG\")\n",
    "        \n",
    "    grayscale_cam = cam3(input_tensor=images, targets=targets)\n",
    "    attention = grayscale_cam * 255\n",
    "    at_map = torch.from_numpy(attention)  # [batch, width, height]\n",
    "    # print('image shape:', images.shape)\n",
    "    # print('at_map shape:', at_map.shape)\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        # save images\n",
    "        label = os.path.basename(paths[i]).split('d')[0]\n",
    "        name = os.path.basename(paths[i])\n",
    "        os.makedirs(os.path.join(mask_path3, str(label)), exist_ok=True)\n",
    "        img = transforms.ToPILImage()(at_map[i] / 255).convert('L')\n",
    "        img.save(os.path.join(mask_path3, str(label), name), \"PNG\")\n",
    "            \n",
    "        \n",
    "# print('Accuracy of test text: %f %%' % (100 * float(correct) / total))\n",
    "# print('number of correct: ', float(correct))\n",
    "#print('ssim_value = {}%'.format(round((ssim_value*100/total), 2)))\n",
    "end = time.time()\n",
    "total_time = int(end-start)\n",
    "m, s = divmod(total_time, 60)\n",
    "h, m = divmod(m, 60)\n",
    "d, h = divmod(h, 24)\n",
    "print('Spend time: %dd %dh %dm %ds' %(d, h, m, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEATMAP ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "start = time.time()\n",
    "# ssim_value=0\n",
    "\n",
    "# Depth_ds \\ Normal_ds\n",
    "dataloaders = DataLoader(\n",
    "    Depth_ds, \n",
    "    batch_size= batch_size, \n",
    "    pin_memory=False,  \n",
    "    shuffle=False)\n",
    "\n",
    "adv_example_path = 'F:\\\\pytorch-grad-cam-master\\\\adv_data\\\\heatmap_grad_depth_eps5_alpha0.5'\n",
    "# mask_path = 'F:\\\\pytorch-grad-cam-master\\\\adv_data\\\\heatmap_grad_depth\\\\mask'\n",
    "\n",
    "os.makedirs(adv_example_path, exist_ok=True)\n",
    "# os.makedirs(mask_path, exist_ok=True)\n",
    "\n",
    "if not os.path.isdir(adv_example_path):\n",
    "    os.mkdir(adv_example_path)\n",
    "adv_type = ['fgsm', 'bim', 'pgd']\n",
    "\n",
    "for adv in adv_type:\n",
    "    if not os.path.isdir(os.path.join(adv_example_path,adv)):\n",
    "        os.mkdir(os.path.join(adv_example_path,adv))\n",
    "\n",
    "fgsm_path = os.path.join(adv_example_path, adv_type[0])\n",
    "bim_path = os.path.join(adv_example_path, adv_type[1])\n",
    "pgd_path = os.path.join(adv_example_path, adv_type[2])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for images, labels, paths in tqdm(dataloaders):\n",
    "    grayscale_cam = cam(input_tensor=images, targets=targets)\n",
    "    at_map = grayscale_cam * 255\n",
    "    \n",
    "    # 單純 heatmap 用法\n",
    "    # at_map = torch.from_numpy(at_map)  # [batch, width, height] 轉成tensor\n",
    "    # for i in range(images.shape[0]):\n",
    "    #     # save images\n",
    "    #     label = os.path.basename(paths[i]).split('d')[0]\n",
    "    #     name = os.path.basename(paths[i])\n",
    "    #     os.makedirs(os.path.join(mask_path, str(label)), exist_ok=True)\n",
    "    #     img = transforms.ToPILImage()(at_map[i] / 255).convert('L')\n",
    "    #     img.save(os.path.join(mask_path, str(label), name), \"PNG\")\n",
    "    \n",
    "    # heatmap + sobel 用法\n",
    "    for i in range(images.shape[0]):\n",
    "        # save images\n",
    "        label = os.path.basename(paths[i]).split('d')[0]\n",
    "        name = os.path.basename(paths[i])\n",
    "        # os.makedirs(os.path.join(mask_path, str(label)), exist_ok=True)\n",
    "        img_path = os.path.join('E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Depth', label, name)\n",
    "        photo = Image.open(img_path)\n",
    "        at_map[i] = grad_cal(at_map[i], photo, threshold=10)\n",
    "        # img = Image.fromarray(np.uint8(at_map[i])).convert('L')\n",
    "        # img.save(os.path.join(mask_path, str(label), name), \"PNG\")\n",
    "    at_map = torch.from_numpy(at_map)\n",
    "    \n",
    "    # [batch, 3, width, height]\n",
    "    at_map = (at_map > 127).to(torch.uint8)\n",
    "    at_map = torch.cat((at_map.unsqueeze(1), at_map.unsqueeze(1), at_map.unsqueeze(1)), dim=1)  # 疊合成三通道 (沒有batch的話疊在dim=0 ; 反之在dim=1)\n",
    "    \n",
    "    fgsm_attack = FGSM(model, eps=5/255, at_map=at_map)\n",
    "    bim_attack = BIM(model, eps=5/255, alpha=0.5/255, steps=10, at_map=at_map)\n",
    "    pgd_attack = PGD(model, eps=5/255, alpha=0.5/255, steps=40, random_start=True, at_map=at_map)\n",
    "    \n",
    "    adv_images_fgsm = fgsm_attack(images, labels)\n",
    "    adv_images_bim = bim_attack(images, labels)\n",
    "    adv_images_pgd = pgd_attack(images, labels)\n",
    "    \n",
    "    adv_images_fgsm = UnNormalize(adv_images_fgsm, mean=mean, std=std)\n",
    "    adv_images_bim = UnNormalize(adv_images_bim, mean=mean, std=std)\n",
    "    adv_images_pgd = UnNormalize(adv_images_pgd, mean=mean, std=std)\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        img_fgsm = transforms.ToPILImage()(adv_images_fgsm[i]).convert('L')\n",
    "        img_bim = transforms.ToPILImage()(adv_images_bim[i]).convert('L')\n",
    "        img_pgd = transforms.ToPILImage()(adv_images_pgd[i]).convert('L')\n",
    "        \n",
    "        label = os.path.basename(paths[i]).split('d')[0]\n",
    "        name = os.path.basename(paths[i])\n",
    "        \n",
    "        if not os.path.isdir(fgsm_path + '\\\\' + str(label)):\n",
    "           os.mkdir(fgsm_path + '\\\\' + str(label))\n",
    "        img_fgsm.save(os.path.join(fgsm_path, str(label), name))\n",
    "        \n",
    "        if not os.path.isdir(bim_path + '\\\\' + str(label)):\n",
    "           os.mkdir(bim_path + '\\\\' + str(label))\n",
    "        img_bim.save(os.path.join(bim_path, str(label), name))\n",
    "        \n",
    "        \n",
    "        if not os.path.isdir(pgd_path + '\\\\' + str(label)):\n",
    "           os.mkdir(pgd_path + '\\\\' + str(label))\n",
    "        img_pgd.save(os.path.join(pgd_path, str(label), name))\n",
    "        \n",
    "    del adv_images_fgsm\n",
    "    del adv_images_bim\n",
    "    del adv_images_pgd  \n",
    "    del at_map \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "        \n",
    "# print('Accuracy of test text: %f %%' % (100 * float(correct) / total))\n",
    "# print('number of correct: ', float(correct))\n",
    "#print('ssim_value = {}%'.format(round((ssim_value*100/total), 2)))\n",
    "end = time.time()\n",
    "total_time = int(end-start)\n",
    "m, s = divmod(total_time, 60)\n",
    "h, m = divmod(m, 60)\n",
    "d, h = divmod(h, 24)\n",
    "print('Spend time: %dd %dh %dm %ds' %(d, h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "dataloaders = DataLoader(\n",
    "    Normal_ds, \n",
    "    batch_size= batch_size, \n",
    "    pin_memory=False,  \n",
    "    shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "start = time.time()\n",
    "# ssim_value=0\n",
    "\n",
    "adv_example_path = 'F:\\\\pytorch-grad-cam-master\\\\adv_data\\\\heatmap_grad_normal_eps5_alpha0.5'\n",
    "# mask_path = 'F:\\\\pytorch-grad-cam-master\\\\adv_data\\\\heatmap_grad_normal\\\\mask'\n",
    "\n",
    "os.makedirs(adv_example_path, exist_ok=True)\n",
    "# os.makedirs(mask_path, exist_ok=True)\n",
    "\n",
    "if not os.path.isdir(adv_example_path):\n",
    "    os.mkdir(adv_example_path)\n",
    "adv_type = ['fgsm', 'bim', 'pgd']\n",
    "\n",
    "for adv in adv_type:\n",
    "    if not os.path.isdir(os.path.join(adv_example_path,adv)):\n",
    "        os.mkdir(os.path.join(adv_example_path,adv))\n",
    "\n",
    "fgsm_path = os.path.join(adv_example_path,'fgsm')\n",
    "bim_path = os.path.join(adv_example_path,'bim')\n",
    "pgd_path = os.path.join(adv_example_path,'pgd')\n",
    "\n",
    "for images, labels, paths in tqdm(dataloaders):\n",
    "    # at_map = None\n",
    "    grayscale_cam = cam(input_tensor=images, targets=targets)\n",
    "    at_map = grayscale_cam * 255\n",
    "    \n",
    "    # 單純 heatmap 用法\n",
    "    # at_map = torch.from_numpy(at_map)  # [batch, width, height] 轉成tensor\n",
    "    # for i in range(images.shape[0]):\n",
    "    #     # save images\n",
    "    #     label = os.path.basename(paths[i]).split('d')[0]\n",
    "    #     name = os.path.basename(paths[i])\n",
    "    #     os.makedirs(os.path.join(mask_path, str(label)), exist_ok=True)\n",
    "    #     img = transforms.ToPILImage()(at_map[i] / 255).convert('L')\n",
    "    #     img.save(os.path.join(mask_path, str(label), name), \"PNG\")\n",
    "    \n",
    "    # heatmap + sobel 用法\n",
    "    for i in range(images.shape[0]):\n",
    "        # save images\n",
    "        label = os.path.basename(paths[i]).split('d')[0]\n",
    "        name = os.path.basename(paths[i])\n",
    "        # os.makedirs(os.path.join(mask_path, str(label)), exist_ok=True)\n",
    "        img_path = os.path.join('E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Normal', label, name)\n",
    "        photo = Image.open(img_path)\n",
    "        at_map[i] = grad_cal(at_map[i], photo, threshold=10)\n",
    "        # img = Image.fromarray(np.uint8(at_map[i])).convert('L')\n",
    "        # img.save(os.path.join(mask_path, str(label), name), \"PNG\")\n",
    "    at_map = torch.from_numpy(at_map)\n",
    "    \n",
    "    # [batch, 3, width, height]\n",
    "    at_map = (at_map > 127).to(torch.uint8)\n",
    "    at_map = torch.cat((at_map.unsqueeze(1), at_map.unsqueeze(1), at_map.unsqueeze(1)), dim=1)  # 疊合成三通道\n",
    "    \n",
    "    fgsm_attack = FGSM(model, eps=5/255, at_map=at_map)\n",
    "    bim_attack = BIM(model, eps=5/255, alpha=0.5/255, steps=10, at_map=at_map)\n",
    "    pgd_attack = PGD(model, eps=5/255, alpha=0.5/255, steps=40, random_start=True, at_map=at_map)\n",
    "    \n",
    "    adv_images_fgsm = fgsm_attack(model, images, labels, device, eps=4/255, at_map=at_map)\n",
    "    adv_images_bim = bim_attack(model, images, labels, device, eps=4/255, alpha=0.5/255, iters=10, at_map=at_map)\n",
    "    adv_images_pgd = pgd_attack(model, images, labels, device, eps=4/255, alpha=0.5/255, at_map=at_map)\n",
    "    \n",
    "    adv_images_fgsm = UnNormalize(adv_images_fgsm, mean=mean, std=std)\n",
    "    adv_images_bim = UnNormalize(adv_images_bim, mean=mean, std=std)\n",
    "    adv_images_pgd = UnNormalize(adv_images_pgd, mean=mean, std=std)\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        img_fgsm = transforms.ToPILImage()(adv_images_fgsm[i]).convert('RGB')\n",
    "        img_bim = transforms.ToPILImage()(adv_images_bim[i]).convert('RGB')\n",
    "        img_pgd = transforms.ToPILImage()(adv_images_pgd[i]).convert('RGB')\n",
    "        \n",
    "        label = os.path.basename(paths[i]).split('d')[0]\n",
    "        name = os.path.basename(paths[i])\n",
    "        \n",
    "        if not os.path.isdir(fgsm_path + '\\\\' + str(label)):\n",
    "           os.mkdir(fgsm_path + '\\\\' + str(label))\n",
    "        img_fgsm.save(os.path.join(fgsm_path, str(label), name))\n",
    "        \n",
    "        if not os.path.isdir(bim_path + '\\\\' + str(label)):\n",
    "           os.mkdir(bim_path + '\\\\' + str(label))\n",
    "        img_bim.save(os.path.join(bim_path, str(label), name))\n",
    "        \n",
    "        \n",
    "        if not os.path.isdir(pgd_path + '\\\\' + str(label)):\n",
    "           os.mkdir(pgd_path + '\\\\' + str(label))\n",
    "        img_pgd.save(os.path.join(pgd_path, str(label), name))\n",
    "        \n",
    "    del adv_images_fgsm\n",
    "    del adv_images_bim\n",
    "    del adv_images_pgd  \n",
    "    del at_map  \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "# print('Accuracy of test text: %f %%' % (100 * float(correct) / total))\n",
    "# print('number of correct: ', float(correct))\n",
    "#print('ssim_value = {}%'.format(round((ssim_value*100/total), 2)))\n",
    "end = time.time()\n",
    "total_time = int(end-start)\n",
    "m, s = divmod(total_time, 60)\n",
    "h, m = divmod(m, 60)\n",
    "d, h = divmod(h, 24)\n",
    "print('Spend time: %dd %dh %dm %ds' %(d, h, m, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "對抗樣本測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# eval\n",
    "\n",
    "# 改成所需的class\n",
    "num_class = 557  # depth: 557\n",
    "model_path = 'E:\\\\LED3D\\\\newData_training\\\\Resnet101\\\\bestModel.pth'  # Resnet101_focal\n",
    "batch_size = 64\n",
    "\n",
    "# Resnet101_focal\n",
    "model = models.resnet101().to(device)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_class).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "model.eval()\n",
    "      \n",
    "mean=[0.5, 0.5, 0.5]\n",
    "std=[0.5, 0.5, 0.5]\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "depth_path = ['F:\\\\pytorch-grad-cam-master\\\\adv_data\\\\heatmap_grad_depth_eps5_alpha0.5']\n",
    "normal_path = ['F:\\\\pytorch-grad-cam-master\\\\adv_data\\\\heatmap_grad_normal_eps5_alpha0.5']\n",
    "attack = ['fgsm', 'bim', 'pgd']\n",
    "for idx in depth_path:\n",
    "    for att in attack:\n",
    "        Depth_dir = os.path.join(idx, str(att))\n",
    "        Depth_ds = IMAGE_Dataset(Depth_dir,trans)\n",
    "        \n",
    "        Depth_dataloaders = DataLoader(\n",
    "            Depth_ds, \n",
    "            batch_size= batch_size, \n",
    "            pin_memory=False,  \n",
    "            shuffle=False)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        ssim_score = 0\n",
    "        wrong = []\n",
    "\n",
    "        for images, labels, paths in tqdm(Depth_dataloaders):\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            total += int(images.shape[0])\n",
    "            correct += (preds == labels).sum()\n",
    "            \n",
    "            for t in range(int(images.shape[0])):\n",
    "                label = os.path.basename(paths[t]).split('d')[0]\n",
    "                name = os.path.basename(paths[t])\n",
    "                img_path = os.path.join('E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Depth', label, name)\n",
    "                image1 = io.imread(paths[t], as_gray=True)  # [256,256,3]\n",
    "                image2 = io.imread(img_path, as_gray=True)  # [256,256,3]\n",
    "                ssim_score += ssim(image1, image2, multichannel=False)\n",
    "                \n",
    "            #     記錄錯誤 csv\n",
    "            #     if preds[t] != labels[t]:\n",
    "            #         wrong.append([paths[t], preds[t], labels[t]])\n",
    "            # torch.cuda.empty_cache()\n",
    "            \n",
    "        print('This is Depth image ' + str(att) + ' attack test:')\n",
    "        print('Accuracy of test text: %f %%' % (100 * float(correct) / total))\n",
    "        print('number of correct: ', float(correct))\n",
    "        print('ssim_value = {}%'.format(round((ssim_score*100/total), 5)))\n",
    "        print('total: ', int(total))\n",
    "\n",
    "        # 寫入csv中查看判別錯誤的log\n",
    "        # csv_name = 'wrong_predict_' + str(att) + '.csv'\n",
    "        # with open(csv_name, 'w', newline='') as csvfile:\n",
    "        #     writer = csv.writer(csvfile)\n",
    "\n",
    "        #     writer.writerow(['path', 'model predict', 'true label'])\n",
    "        #     # 寫入二維表格\n",
    "        #     writer.writerows(wrong)\n",
    "        # del wrong\n",
    "        \n",
    "torch.cuda.empty_cache()\n",
    "print('-------------------------------------')\n",
    "\n",
    "for idx in normal_path: \n",
    "    for att in attack:\n",
    "        Normal_dir = os.path.join(idx, str(att))\n",
    "        Normal_ds = IMAGE_Dataset(Normal_dir,trans)\n",
    "\n",
    "        Normal_dataloaders = DataLoader(\n",
    "            Normal_ds, \n",
    "            batch_size= batch_size, \n",
    "            pin_memory=False,  \n",
    "            shuffle=False)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        ssim_score = 0\n",
    "        wrong = []\n",
    "\n",
    "        for images, labels, paths in tqdm(Normal_dataloaders):\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            total += int(images.shape[0])\n",
    "            correct += (preds == labels).sum()\n",
    "            \n",
    "            \n",
    "            for t in range(int(images.shape[0])):\n",
    "                label = os.path.basename(paths[t]).split('d')[0]\n",
    "                name = os.path.basename(paths[t])\n",
    "                img_path = os.path.join('E:\\\\3D_dataset\\\\FRGC\\\\FRGC-2.0-dist\\\\nd1\\\\0908newData\\\\LabelData_Normal', label, name)\n",
    "                image1 = io.imread(paths[t], as_gray=False)  # [256,256,3]\n",
    "                image2 = io.imread(img_path, as_gray=False)  # [256,256,3]\n",
    "                ssim_score += ssim(image1, image2, multichannel=True)\n",
    "                \n",
    "                # 記錄錯誤\n",
    "                # if preds[t] != labels[t]:\n",
    "                #     wrong.append([paths[t], preds[t], labels[t]])\n",
    "                \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        print('This is Normal image ' + str(att) + ' attack test:')    \n",
    "        print('Accuracy of test text: %f %%' % (100 * float(correct) / total))\n",
    "        print('number of correct: ', float(correct))\n",
    "        print('ssim_value = {}%'.format(round((ssim_score*100/total), 5)))\n",
    "        print('total: ', int(total))\n",
    "\n",
    "        # 寫入csv中查看判別錯誤的log\n",
    "        # csv_name = 'wrong_predict_' + str(att) + '.csv'\n",
    "        # with open(csv_name, 'w', newline='') as csvfile:\n",
    "        #     writer = csv.writer(csvfile)\n",
    "\n",
    "        #     writer.writerow(['path', 'model predict', 'true label'])\n",
    "        #     # 寫入二維表格\n",
    "        #     writer.writerows(wrong)\n",
    "        # del wrong\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
